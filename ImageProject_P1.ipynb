{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageProject_P1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HerLVDVRuvUy",
        "EMluPvxJvBE1",
        "YF77KdAd4eKQ",
        "L4qXO0fg9fgT"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Project Phase one: Lane Detection**\n",
        "the goal is to write a software pipeline to detect the lane boundaries in a video from a front-facing camera on a car. itâ€™s required to find and track the lane lines and the position of the car from the center of the lane.\n",
        "As a bonus, track the radius of curvature of the road too.\n",
        "\n",
        "Assume the camera is mounted at the center of the car, such that the lane center is the midpoint at the bottom of the image between the two lines you've detected.\n",
        "\n",
        "The offset of the lane center from the center of the image (converted from pixels to meters) is your distance from the center of the lane."
      ],
      "metadata": {
        "id": "wLJP6y1luR_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 0: Import Libraries & Debug Flag"
      ],
      "metadata": {
        "id": "HerLVDVRuvUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from moviepy.editor import VideoFileClip"
      ],
      "metadata": {
        "id": "YKz9j3Ctu13S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Prespective Transformation Function (Bird's Eye)"
      ],
      "metadata": {
        "id": "EMluPvxJvBE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Transformation Function (Normal ---> Bird'sEye)\"\"\"\n",
        "def bird_forward(img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
        "    #Coordinates of input image\n",
        "    input = np.float32([(550, 460),     # top-left\n",
        "                            (150, 720),     # bottom-left\n",
        "                            (1200, 720),    # bottom-right\n",
        "                            (770, 460)])    # top-right\n",
        "    #Coordinates of Output Image\n",
        "    output = np.float32([(100, 0),\n",
        "                            (100, 720),\n",
        "                            (1100, 720),\n",
        "                            (1100, 0)])\n",
        "    #Transformation Matrix Calculation (Normal --> Bird's Eye)\n",
        "    Mat = cv2.getPerspectiveTransform(input, output)\n",
        "    return cv2.warpPerspective(img, Mat, img_size, flags=flags)\n",
        "\n",
        "\"\"\"Inverse Transformation Function (Bird'sEye ---> Normal)\"\"\"\n",
        "def bird_backward(img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
        "    #Coordinates of Input Image\n",
        "    input = np.float32([(100, 0),\n",
        "                            (100, 720),\n",
        "                            (1100, 720),\n",
        "                            (1100, 0)])\n",
        "    #Coordinates of Output image\n",
        "    output = np.float32([(550, 460),     # top-left\n",
        "                            (150, 720),     # bottom-left\n",
        "                            (1200, 720),    # bottom-right\n",
        "                            (770, 460)])    # top-right\n",
        "    #Inverse Transformation Matrix Calculation  (Bird's Eye --> Normal)\n",
        "    Mat_inv = cv2.getPerspectiveTransform(input, output)\n",
        "    return cv2.warpPerspective(img, Mat_inv, img_size, flags=flags)"
      ],
      "metadata": {
        "id": "qNqf8Vx2vOec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Lines Detection Function "
      ],
      "metadata": {
        "id": "cTteD9izv4Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Relative Threshold Method\"\"\"\n",
        "def threshold_rel(img, lo, hi):\n",
        "    vmin = np.min(img)\n",
        "    vmax = np.max(img)\n",
        "    vlo = vmin + (vmax - vmin) * lo\n",
        "    vhi = vmin + (vmax - vmin) * hi\n",
        "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
        "\n",
        "\"\"\"Absolute Threshold Method\"\"\"\n",
        "def threshold_abs(img, lo, hi):\n",
        "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
        "\n",
        "\"\"\"Lane Detection Function\"\"\"\n",
        "def lines_detection(bird_img):\n",
        "    hls = cv2.cvtColor(bird_img, cv2.COLOR_RGB2HLS)\n",
        "    hsv = cv2.cvtColor(bird_img, cv2.COLOR_RGB2HSV)\n",
        "    gray = cv2.cvtColor(bird_img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    h_channel = hls[:,:,0]\n",
        "    l_channel = hls[:,:,1]\n",
        "    s_channel = hls[:,:,2]\n",
        "    v_channel = hsv[:,:,2]\n",
        "\n",
        "    right_lane = threshold_rel(l_channel, 0.8, 1.0)   #White Detection\n",
        "    right_lane[:,:750] = 0\n",
        "\n",
        "    left_lane = threshold_abs(h_channel, 20, 40)      #Yellow Detection\n",
        "    left_lane &= threshold_rel(v_channel, 0.7, 1.0)   #Color Value (Strenth)\n",
        "    left_lane[:,550:] = 0\n",
        "\n",
        "    out = left_lane | right_lane                     #Compose The Two Sides\n",
        "    return gray,out"
      ],
      "metadata": {
        "id": "tXgn5m-RwCEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Lane Detection Function"
      ],
      "metadata": {
        "id": "YF77KdAd4eKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LaneLines:\n",
        "    def __init__(self):\n",
        "        self.left_fit = None\n",
        "        self.right_fit = None\n",
        "        self.binary = None\n",
        "        self.nonzero = None\n",
        "        self.nonzerox = None\n",
        "        self.nonzeroy = None\n",
        "        self.clear_visibility = True\n",
        "        self.dir = []\n",
        "    \n",
        "        # HYPERPARAMETERS\n",
        "        # Number of sliding windows\n",
        "        self.nwindows = 9\n",
        "        # Width of the the windows +/- margin\n",
        "        self.margin = 100\n",
        "        # Mininum number of pixels found to recenter window\n",
        "        self.minpix = 50\n",
        "    \n",
        "    def forward(self, img):\n",
        "        self.extract_features(img)\n",
        "        return self.fit_poly(img)\n",
        "\n",
        "    def fit_poly(self, img):\n",
        "        out = np.dstack((img, img, img))\n",
        "        leftx, lefty, rightx, righty, out_img = self.find_lane_pixels(img)\n",
        "\n",
        "        if len(lefty) > 1500:\n",
        "            self.left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        if len(righty) > 1500:\n",
        "            self.right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "        # Generate x and y values for plotting\n",
        "        maxy = img.shape[0] - 1\n",
        "        miny = img.shape[0] // 3\n",
        "        if len(lefty):\n",
        "            maxy = max(maxy, np.max(lefty))\n",
        "            miny = min(miny, np.min(lefty))\n",
        "\n",
        "        if len(righty):\n",
        "            maxy = max(maxy, np.max(righty))\n",
        "            miny = min(miny, np.min(righty))\n",
        "\n",
        "        ploty = np.linspace(miny, maxy, img.shape[0])\n",
        "\n",
        "        left_fitx = self.left_fit[0]*ploty**2 + self.left_fit[1]*ploty + self.left_fit[2]\n",
        "        right_fitx = self.right_fit[0]*ploty**2 + self.right_fit[1]*ploty + self.right_fit[2]\n",
        "\n",
        "        # Visualization\n",
        "        c = 0\n",
        "        for i, y in enumerate(ploty):\n",
        "            c = c+1\n",
        "            if(c == 2):\n",
        "                yo = int(y)\n",
        "                lo = int(l)\n",
        "                ro = int(r)\n",
        "            y = int(ploty[i])\n",
        "            l = int(left_fitx[i])\n",
        "            r = int(right_fitx[i])\n",
        "            cv2.line(out, (l, y), (r, y), (0, 255, 0),20)\n",
        "            if(c == 100):\n",
        "                c = 0\n",
        "                cv2.line(out,(lo,yo),(l,y), (255,0,0), 50)\n",
        "                cv2.line(out,(ro,yo),(r,y), (255,0,0), 50)\n",
        "\n",
        "        return out, out_img\n",
        "\n",
        "    def extract_features(self, img):\n",
        "        self.img = img\n",
        "        # Height of of windows - based on nwindows and image shape\n",
        "        self.window_height = np.int(img.shape[0]//self.nwindows)\n",
        "    \n",
        "        # Identify the x and y positions of all nonzero pixel in the image\n",
        "        self.nonzero = img.nonzero()\n",
        "        \n",
        "        self.nonzerox = np.array(self.nonzero[1])\n",
        "        self.nonzeroy = np.array(self.nonzero[0])\n",
        "\n",
        "    def find_lane_pixels(self, img):\n",
        "        assert(len(img.shape) == 2)\n",
        "\n",
        "        # Create an output image to draw on and visualize the result\n",
        "        out_img = np.dstack((img, img, img))\n",
        "\n",
        "       \n",
        "        bottom_half = img[img.shape[0]//2:,:]\n",
        "        histogram =  np.sum(bottom_half, axis=0)\n",
        "\n",
        "        midpoint = histogram.shape[0]//2\n",
        "\n",
        "         # Peak in the first half indicates the likely position of the left lane\n",
        "        leftx_base = np.argmax(histogram[:midpoint])\n",
        "\n",
        "        # Peak in the second half indicates the likely position of the right lane\n",
        "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "        # Current position to be update later for each window in nwindows\n",
        "        leftx_current = leftx_base\n",
        "        rightx_current = rightx_base\n",
        "        y_current = img.shape[0] + self.window_height//2\n",
        "\n",
        "        # Create empty lists to reveice left and right lane pixel\n",
        "        leftx, lefty, rightx, righty = [], [], [], []\n",
        "\n",
        "        # Step through the windows one by one\n",
        "        for window in range(self.nwindows):\n",
        "            # Identify window boundaries in x and y (and right and left)\n",
        "            win_y_low = img.shape[0] - (window+1)*self.window_height\n",
        "            win_y_high = img.shape[0] - window*self.window_height\n",
        "            win_xleft_low = leftx_current - self.margin\n",
        "            win_xleft_high = leftx_current +self. margin\n",
        "            win_xright_low = rightx_current - self.margin\n",
        "            win_xright_high = rightx_current + self.margin\n",
        "\n",
        "            # Draw the windows on the visualization image\n",
        "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
        "            (0,255,0), 2) \n",
        "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
        "            (0,255,0), 2) \n",
        "\n",
        "            y_current -= self.window_height\n",
        "            center_left = (leftx_current, y_current)\n",
        "            center_right = (rightx_current, y_current)\n",
        "\n",
        "            good_left_x, good_left_y = self.pixels_in_window(center_left, self.margin, self.window_height)\n",
        "            good_right_x, good_right_y = self.pixels_in_window(center_right, self.margin, self.window_height)\n",
        "\n",
        "            # Append these indices to the lists\n",
        "            leftx.extend(good_left_x)\n",
        "            lefty.extend(good_left_y)\n",
        "            rightx.extend(good_right_x)\n",
        "            righty.extend(good_right_y)\n",
        "\n",
        "            # If you found > minpix pixels, recenter next window on their mean position\n",
        "            if len(good_left_x) > self.minpix:\n",
        "                leftx_current = np.int32(np.mean(good_left_x))\n",
        "            if len(good_right_x) > self.minpix:\n",
        "                rightx_current = np.int32(np.mean(good_right_x))\n",
        "\n",
        "        return leftx, lefty, rightx, righty, out_img\n",
        "\n",
        "    def pixels_in_window(self, center, margin, height):\n",
        "        topleft = (center[0]-margin, center[1]-height//2)\n",
        "        bottomright = (center[0]+margin, center[1]+height//2)\n",
        "\n",
        "        condx = (topleft[0] <= self.nonzerox) & (self.nonzerox <= bottomright[0])\n",
        "        condy = (topleft[1] <= self.nonzeroy) & (self.nonzeroy <= bottomright[1])\n",
        "        return self.nonzerox[condx&condy], self.nonzeroy[condx&condy]\n",
        "\n",
        "    def measure_curvature(self):\n",
        "        ym = 30/720\n",
        "        xm = 3.7/700\n",
        "\n",
        "        left_fit = self.left_fit.copy()\n",
        "        right_fit = self.right_fit.copy()\n",
        "        y_eval = 700 * ym\n",
        "\n",
        "        # Compute R_curve (radius of curvature)\n",
        "        left_curveR =  ((1 + (2*left_fit[0] *y_eval + left_fit[1])**2)**1.5)  / np.absolute(2*left_fit[0])\n",
        "        right_curveR = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
        "\n",
        "        xl = np.dot(self.left_fit, [700**2, 700, 1])\n",
        "        xr = np.dot(self.right_fit, [700**2, 700, 1])\n",
        "        pos = (1280//2 - (xl+xr)//2)*xm\n",
        "        return left_curveR, right_curveR, pos"
      ],
      "metadata": {
        "id": "lh9Bl0D_4dLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Adjust The Original Frame"
      ],
      "metadata": {
        "id": "L4qXO0fg9fgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_frame(blend_on_road, bird_img, gray_img, lines_img, window_img, highlight_img, Rcurve, Lcurve, pos):\n",
        "    #Prepare the final pretty pretty output blend, given all intermediate pipeline images\n",
        "    h, w = blend_on_road.shape[:2]\n",
        "\n",
        "    thumb_ratio = 0.17\n",
        "    thumb_h, thumb_w = int(thumb_ratio * h), int(thumb_ratio * w)\n",
        "\n",
        "    off_x, off_y = 15, 15\n",
        "\n",
        "    # add a gray rectangle at the right\n",
        "    mask = blend_on_road.copy()\n",
        "    mask = cv2.rectangle(mask, pt1=(w-(thumb_w+off_x*2), 0), pt2=(w, h), color=(50, 50, 50), thickness=cv2.FILLED)\n",
        "    blend_on_road = cv2.addWeighted(src1=mask, alpha=0.2, src2=blend_on_road, beta=0.8, gamma=0)\n",
        "\n",
        "    # add thumbnail of bird\n",
        "    thumb_bird = cv2.resize(bird_img, dsize=(thumb_w, thumb_h))\n",
        "    blend_on_road[off_y:thumb_h+off_y, w-(thumb_w+off_x):w-off_x, :] = thumb_bird\n",
        "\n",
        "    # add thumbnail of gray\n",
        "    thumb_gray = cv2.resize(gray_img, dsize=(thumb_w, thumb_h))\n",
        "    thumb_gray = np.dstack([thumb_gray, thumb_gray, thumb_gray]) \n",
        "    blend_on_road[thumb_h+(off_y*2):(thumb_h*2)+(off_y*2), w-(thumb_w+off_x):w-off_x, :] = thumb_gray\n",
        "\n",
        "    # add thumbnail of lines\n",
        "    thumb_lines = cv2.resize(lines_img, dsize=(thumb_w, thumb_h))\n",
        "    thumb_lines = np.dstack([thumb_lines, thumb_lines, thumb_lines])\n",
        "    blend_on_road[(thumb_h*2)+(off_y*3):(thumb_h*3)+(off_y*3), w-(thumb_w+off_x):w-off_x, :] = thumb_lines\n",
        "    \n",
        "    # add thumbnail of window\n",
        "    thumb_window = cv2.resize(window_img, dsize=(thumb_w, thumb_h))\n",
        "    blend_on_road[(thumb_h*3)+(off_y*4):(thumb_h*4)+(off_y*4), w-(thumb_w+off_x):w-off_x, :] = thumb_window\n",
        "\n",
        "    # add thumbnail of highlight\n",
        "    thumb_highlight = cv2.resize(highlight_img, dsize=(thumb_w, thumb_h))\n",
        "    blend_on_road[(thumb_h*4)+(off_y*5):(thumb_h*5)+(off_y*5), w-(thumb_w+off_x):w-off_x, :] = thumb_highlight\n",
        "\n",
        "    # add text (curvature and offset info) on the upper right of the blend\n",
        "    mean_curvature_meter = np.mean([Lcurve, Rcurve])\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(blend_on_road, 'Curvature radius: ', (off_x, (2*off_y)+20), font, 0.9, (200, 200, 200), 2, cv2.LINE_AA)\n",
        "    cv2.putText(blend_on_road, '   {:.02f}m'.format(mean_curvature_meter), (off_x, (2*off_y)+70), font, 0.9, (150, 100, 0), 2, cv2.LINE_AA)\n",
        "    cv2.putText(blend_on_road, 'Offset from center: ', (off_x + 300, (2*off_y)+20), font, 0.9, (200, 200, 200), 2, cv2.LINE_AA)\n",
        "    cv2.putText(blend_on_road, '   {:.02f}m'.format(pos), (off_x + 300, (2*off_y)+70), font, 0.9, (150, 100, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    return blend_on_road"
      ],
      "metadata": {
        "id": "h5kB3_tI9peV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Apply Functions to every Video's Frame"
      ],
      "metadata": {
        "id": "KqxuQ-lOxLqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Global Var\"\"\"\n",
        "lanelines = LaneLines()\n",
        "\n",
        "\"\"\"Cumculative Function\"\"\"\n",
        "def process_image(img):\n",
        "    #Step One: Transform the prespective of image to birdeye\n",
        "    bird_img = bird_forward(img)\n",
        "    #Step Two: Lines Detection By Apply Filters\n",
        "    gray_img , lines_img = lines_detection(bird_img)\n",
        "    #Step Three: Lane Detection and Curvature Calculation\n",
        "    highlight_lane_img, window_img = lanelines.forward(lines_img)\n",
        "    Lc, Rc, pos = lanelines.measure_curvature()\n",
        "    #Step Four: Merge the Highlighted Lane and Original Picture\n",
        "    reverse_view_img = bird_backward(highlight_lane_img)\n",
        "    final_img = cv2.addWeighted(img, 1, reverse_view_img, 1, 0)\n",
        "    #Step Five: Show Step By Step Frame, Curvature, and Distance of Center (((IF THE DEBUG FLAG EQUALS ONE)))\n",
        "    if(debug == 1):\n",
        "      final_img = prepare_frame(final_img, bird_img, gray_img, lines_img, window_img, highlight_lane_img, Lc,Rc, pos )\n",
        "    return final_img"
      ],
      "metadata": {
        "id": "xFLaF_UOxY1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = [\"challenge\", \"project\"]\n",
        "index = 0\n",
        "debug = 1  #FLAG\n",
        "clip = VideoFileClip(\"{}_video.mp4\".format(video[index]))\n",
        "out_clip = clip.fl_image(process_image)\n",
        "out_clip.write_videofile(\"out_{}_video.mp4\".format(video[index]), audio=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9GRvIZK-IbW",
        "outputId": "5651853f-2605-4416-ebf2-218018046e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] >>>> Building video out_challenge_video.mp4\n",
            "[MoviePy] Writing video out_challenge_video.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 394/485 [00:58<00:13,  6.78it/s]"
          ]
        }
      ]
    }
  ]
}